{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load the dataset\n",
    "file_path = '/mnt/data/random_user_movie_ratings.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Display the dataset\n",
    "print(\"Dataset Head:\")\n",
    "print(df.head())\n",
    "\n",
    "# 1. Adjust ratings to 1-5 scale\n",
    "print(\"\\nRescaling ratings to 1-5 scale...\")\n",
    "df['rating'] = df['rating'].clip(lower=1, upper=5)\n",
    "\n",
    "# 2. Total number of users and items\n",
    "tnu = df['user_id'].nunique()\n",
    "tni = df['item_id'].nunique()\n",
    "print(f\"\\nTotal number of users (tnu): {tnu}\")\n",
    "print(f\"Total number of items (tni): {tni}\")\n",
    "\n",
    "# 3. Count ratings for each product\n",
    "item_rating_counts = df['item_id'].value_counts()\n",
    "print(\"\\nNumber of ratings per item:\")\n",
    "print(item_rating_counts)\n",
    "\n",
    "# 4. Select 3 active users (U1, U2, U3) with different missing ratings\n",
    "print(\"\\nSelecting active users (U1, U2, U3)...\")\n",
    "active_users = {}\n",
    "active_users['U1'] = df['user_id'].value_counts().index[0]  # User with most ratings\n",
    "active_users['U2'] = df['user_id'].value_counts().index[1]\n",
    "active_users['U3'] = df['user_id'].value_counts().index[2]\n",
    "\n",
    "# 5. Select 2 target items (I1, I2) with missing ratings\n",
    "print(\"\\nSelecting target items (I1, I2)...\")\n",
    "target_items = {}\n",
    "item_missing = df['item_id'].value_counts(ascending=True)\n",
    "target_items['I1'] = item_missing.index[0]  # Item with 4% missing ratings\n",
    "target_items['I2'] = item_missing.index[1]  # Item with 10% missing ratings\n",
    "\n",
    "print(f\"Active Users: {active_users}\")\n",
    "print(f\"Target Items: {target_items}\")\n",
    "\n",
    "# 6. Count co-rated items and common users\n",
    "print(\"\\nCounting co-rated items and common users...\")\n",
    "user_item_matrix = df.pivot_table(index='user_id', columns='item_id', values='rating')\n",
    "co_rated_items = (user_item_matrix.notna() & user_item_matrix.notna().loc[active_users['U1']]).sum(axis=1)\n",
    "\n",
    "common_users = {}\n",
    "for user in active_users.values():\n",
    "    common_users[user] = (user_item_matrix.notna().sum(axis=1) >= 1).sum()\n",
    "\n",
    "# 7. Create a 2D array for descending No_common_users and No_coRated_items\n",
    "print(\"\\nCreating a 2D array for No_common_users and No_coRated_items...\")\n",
    "no_common_users = co_rated_items.sort_values(ascending=False)\n",
    "no_cRated_items = user_item_matrix.loc[active_users['U1']].notna().sum()\n",
    "\n",
    "array_2D = np.column_stack((no_common_users, no_cRated_items))\n",
    "print(array_2D)\n",
    "\n",
    "# 8. Visualization: Ratings per item\n",
    "print(\"\\nDrawing curve for quantity of ratings per item...\")\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(item_rating_counts.sort_index(), marker='o')\n",
    "plt.xlabel('Item ID')\n",
    "plt.ylabel('Number of Ratings')\n",
    "plt.title('Quantity of Ratings for Each Item')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# 9. Threshold Beta for active users\n",
    "print(\"\\nDetermining threshold Beta for active users...\")\n",
    "thresholds = {}\n",
    "for user in active_users.values():\n",
    "    co_rated = (user_item_matrix.notna() & user_item_matrix.notna().loc[user]).sum(axis=1)\n",
    "    thresholds[user] = (co_rated >= 0.3 * tni).sum()\n",
    "\n",
    "print(f\"Thresholds (Beta) for Active Users: {thresholds}\")\n",
    "\n",
    "# 10. Save results\n",
    "results = {\n",
    "    'Total Users': tnu,\n",
    "    'Total Items': tni,\n",
    "    \n",
    "    'Active Users': active_users,\n",
    "    'Target Items': target_items,\n",
    "    'Thresholds': thresholds\n",
    "}\n",
    "results_df = pd.DataFrame.from_dict(results, orient='index')\n",
    "results_df.to_csv('results_summary.csv', index=True)\n",
    "print(\"\\nResults saved to 'results_summary.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# Helper function for mean-centering\n",
    "def mean_centering(matrix):\n",
    "    return matrix.subtract(matrix.mean(axis=1), axis=0)\n",
    "\n",
    "# Load dataset again (item-based CF)\n",
    "print(\"\\nLoading dataset for Item-Based Collaborative Filtering...\")\n",
    "item_based_df = df.copy()\n",
    "item_user_matrix = item_based_df.pivot_table(index='item_id', columns='user_id', values='rating')\n",
    "\n",
    "# ------------------- CASE STUDY 2.2: ITEM-BASED CF USING COSINE SIMILARITY -------------------\n",
    "\n",
    "print(\"\\n--- Case Study 2.2: Cosine Similarity with Mean-Centering ---\")\n",
    "\n",
    "# 2.2.1 Apply item-based CF using Cosine similarity with mean-centering\n",
    "print(\"Applying mean-centering and computing Cosine similarity...\")\n",
    "mean_centered_item_matrix = mean_centering(item_user_matrix)\n",
    "\n",
    "# Compute Cosine similarity between items\n",
    "cosine_sim_matrix = cosine_similarity(mean_centered_item_matrix.fillna(0))\n",
    "cosine_sim_df = pd.DataFrame(cosine_sim_matrix, index=mean_centered_item_matrix.index, columns=mean_centered_item_matrix.index)\n",
    "\n",
    "print(\"\\nCosine Similarity Matrix (Sample):\")\n",
    "print(cosine_sim_df.head())\n",
    "\n",
    "# 2.2.2 Determine top 20% closest items for each target item\n",
    "top_20_percent_items = {}\n",
    "for item in target_items.values():\n",
    "    closest_items = cosine_sim_df[item].sort_values(ascending=False)[1:]  # Exclude itself\n",
    "    top_20_percent_items[item] = closest_items.head(int(0.2 * len(closest_items)))\n",
    "\n",
    "print(\"\\nTop 20% Closest Items:\")\n",
    "for item, closest in top_20_percent_items.items():\n",
    "    print(f\"Target Item {item}:\\n{closest}\")\n",
    "\n",
    "# 2.2.3 Predict missing ratings for each target item\n",
    "predicted_ratings = {}\n",
    "for item in target_items.values():\n",
    "    closest_items = top_20_percent_items[item]\n",
    "    known_ratings = item_user_matrix.loc[closest_items.index]\n",
    "    predicted_ratings[item] = known_ratings.mean(axis=0)\n",
    "\n",
    "print(\"\\nPredicted Ratings for Target Items (Case 2.2):\")\n",
    "print(predicted_ratings)\n",
    "\n",
    "# 2.2.4 Compute Discount Factor (DF) and Discounted Similarity (DS)\n",
    "print(\"\\nComputing Discount Factor and Discounted Similarity...\")\n",
    "thresholds = thresholds  # Beta values computed earlier\n",
    "discounted_similarity = {}\n",
    "for item in target_items.values():\n",
    "    df = 1 / (1 + np.exp(-thresholds[active_users['U1']]))\n",
    "    discounted_similarity[item] = cosine_sim_df[item] * df\n",
    "\n",
    "# 2.2.5 Determine top 20% closest items using discounted similarity\n",
    "top_20_percent_ds_items = {}\n",
    "for item in target_items.values():\n",
    "    closest_ds_items = discounted_similarity[item].sort_values(ascending=False)[1:]\n",
    "    top_20_percent_ds_items[item] = closest_ds_items.head(int(0.2 * len(closest_ds_items)))\n",
    "\n",
    "print(\"\\nTop 20% Closest Items using Discounted Similarity:\")\n",
    "for item, closest in top_20_percent_ds_items.items():\n",
    "    print(f\"Target Item {item}:\\n{closest}\")\n",
    "\n",
    "# 2.2.6 Predict missing ratings using discounted similarity\n",
    "predicted_ds_ratings = {}\n",
    "for item in target_items.values():\n",
    "    closest_items = top_20_percent_ds_items[item]\n",
    "    known_ratings = item_user_matrix.loc[closest_items.index]\n",
    "    predicted_ds_ratings[item] = known_ratings.mean(axis=0)\n",
    "\n",
    "print(\"\\nPredicted Ratings using Discounted Similarity (Case 2.2):\")\n",
    "print(predicted_ds_ratings)\n",
    "\n",
    "# ------------------- CASE STUDY 2.3: ITEM-BASED CF USING PCC -------------------\n",
    "\n",
    "print(\"\\n--- Case Study 2.3: Pearson Correlation Coefficient (PCC) ---\")\n",
    "\n",
    "# 2.3.1 Apply item-based CF using PCC\n",
    "def compute_pcc(matrix):\n",
    "    items = matrix.index\n",
    "    pcc_matrix = pd.DataFrame(index=items, columns=items, dtype=float)\n",
    "    for i in items:\n",
    "        for j in items:\n",
    "            if i != j:\n",
    "                valid_ratings = matrix.loc[[i, j]].dropna(axis=1)\n",
    "                if len(valid_ratings.columns) > 1:\n",
    "                    pcc_matrix.loc[i, j] = pearsonr(valid_ratings.loc[i], valid_ratings.loc[j])[0]\n",
    "    return pcc_matrix.fillna(0)\n",
    "\n",
    "print(\"Computing Pearson Correlation Coefficient (PCC)...\")\n",
    "pcc_sim_matrix = compute_pcc(item_user_matrix)\n",
    "\n",
    "print(\"\\nPCC Similarity Matrix (Sample):\")\n",
    "print(pcc_sim_matrix.head())\n",
    "\n",
    "# 2.3.2 Determine top 20% closest items for each target item\n",
    "top_20_percent_pcc_items = {}\n",
    "for item in target_items.values():\n",
    "    closest_items = pcc_sim_matrix[item].sort_values(ascending=False)[1:]  # Exclude itself\n",
    "    top_20_percent_pcc_items[item] = closest_items.head(int(0.2 * len(closest_items)))\n",
    "\n",
    "print(\"\\nTop 20% Closest Items (PCC):\")\n",
    "for item, closest in top_20_percent_pcc_items.items():\n",
    "    print(f\"Target Item {item}:\\n{closest}\")\n",
    "\n",
    "# 2.3.3 Predict missing ratings for target items using PCC\n",
    "predicted_pcc_ratings = {}\n",
    "for item in target_items.values():\n",
    "    closest_items = top_20_percent_pcc_items[item]\n",
    "    known_ratings = item_user_matrix.loc[closest_items.index]\n",
    "    predicted_pcc_ratings[item] = known_ratings.mean(axis=0)\n",
    "\n",
    "print(\"\\nPredicted Ratings for Target Items (PCC):\")\n",
    "print(predicted_pcc_ratings)\n",
    "\n",
    "# ------------------ COMPARISON OF RESULTS ------------------\n",
    "\n",
    "# Compare top 20% closest items\n",
    "print(\"\\nComparison of Top 20% Closest Items:\")\n",
    "for item in target_items.values():\n",
    "    print(f\"\\nTarget Item {item}:\")\n",
    "    print(f\"Cosine Similarity:\\n{top_20_percent_items[item]}\")\n",
    "    print(f\"Discounted Cosine Similarity:\\n{top_20_percent_ds_items[item]}\")\n",
    "    print(f\"PCC Similarity:\\n{top_20_percent_pcc_items[item]}\")\n",
    "\n",
    "# Compare predictions\n",
    "print(\"\\nComparison of Predicted Ratings:\")\n",
    "for item in target_items.values():\n",
    "    print(f\"\\nTarget Item {item}:\")\n",
    "    print(f\"Cosine Similarity Prediction:\\n{predicted_ratings[item]}\")\n",
    "    print(f\"Discounted Cosine Similarity Prediction:\\n{predicted_ds_ratings[item]}\")\n",
    "    print(f\"PCC Prediction:\\n{predicted_pcc_ratings[item]}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
